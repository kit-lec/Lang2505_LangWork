{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f0bcf2-432b-48db-90a8-203a074221a4",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "https://python.langchain.com/api_reference/langchain/memory.html\n",
    "\n",
    "챗봇으로 하여금 대화(상태)를 '기억'하게끔 한다\n",
    "\n",
    "Memory maintains Chain state, incorporating context from past runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300eee3-9375-4d5f-acad-d2667af7b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain 의 memory 계층\n",
    "#  BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690ed2fa-fa89-4701-b6d0-400295c5a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 사에서 제공하는 '기본 API' 도 랭체인 없이 사용 가능.\n",
    "# 메모리 지원하지 않는다.  이전 대화 기억 못함.  stateless 하다!\n",
    "\n",
    "# ChatGPT 서비스 는 '메모리' 기능이 탑재되어 있다.\n",
    "# 챗봇이 이전의 대화 내용과 질문을 기억하고 답할수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a461a-c6d9-4696-83ed-62fb6ab4ed3e",
   "metadata": {},
   "source": [
    "# 기본 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f7c678c-0f26-49ad-a111-054218780d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679784c7-9eaa-43f9-8b0c-ac5939aebeea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f02e59a-7392-49f5-8c52-35b8dc3acb04",
   "metadata": {},
   "source": [
    "# ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c89aea8-24a9-48aa-975a-df42563b4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationBufferMemory\n",
    "# 대화 내용 '전체'를 저장하는 메모리\n",
    "\n",
    "# 장점: 단순하다\n",
    "\n",
    "# 단점:\n",
    "# => 매번 요청할때마다 '이전 대화 기록 전체' 를 같이 보내야 함.\n",
    "#  그래야 모델이 전에 일어났던 대화를 보고 이해 할수 있다.\n",
    "#  대화내용이 길어질수록 메모리도 계속 커지니까 성능적으로도 & 비용적으로도 비효율적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2286e5da-e2ff-4b6a-8b24-102299346941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "# https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#conversationbuffermemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad41f81-a3e2-4df3-a5e0-602284b05beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23164\\346152885.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi!\\nAI: How are you?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi!\"},\n",
    "    {'output': 'How are you?'}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})  # history buffer 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0308cbc-9e0b-42ea-a291-e8b0d0ea3ef3",
   "metadata": {},
   "source": [
    "## return_messages=True\n",
    "history 에  AIMessage 와 HumanMessage 로 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e4dc05-78d0-456c-b785-a7ad16daef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi!\"},\n",
    "    {'output': 'How are you?'}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7615a05c-3775-4083-984e-fe1a64a33dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Hi!\"},\n",
    "    {'output': 'How are you?'}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea35cee-0b35-4147-86cc-1ef69d03cd0d",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876c3c6a-aea6-4c75-a26d-71fb1e4779b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain.memory.buffer_window import ConversationBufferWindowMemory\n",
    "# https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html#conversationbufferwindowmemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75fb2ad-67b8-4a34-8b7b-2d778787c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationBufferWindowMemory 는 대화의 '특정 부분만' 을 저장하는 메모리.\n",
    "\n",
    "# 장점:\n",
    "#   메모리를 특정 크기로 유지할 수 있다!\n",
    "#   따라서 모든 대화 내용을 저장하지 않아도 된다!\n",
    "\n",
    "# 단점:\n",
    "#   챗봇이 전체 대화가 아닌 '최근 대화' 에만 집중하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b430cc28-0133-44dc-bce9-dca457e9f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23164\\2681781434.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4,   # 버퍼 윈도우 사이즈,  몇개의 메세지를 저장할지 지정.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "196947a8-a2b2-4ae6-b574-1c71a91f676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도우미 함수 하나 준비.  여러 메세지를 추가하기 편리하니까\n",
    "def add_message(input, output):\n",
    "  memory.save_context({\"input\": input}, {\"output\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555ce793-671e-4372-b846-462ba4b43c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"1\", \"1\")\n",
    "add_message(\"2\", \"2\")\n",
    "add_message(\"3\", \"3\")\n",
    "add_message(\"4\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4feb5d-bb6a-4be3-8ae3-13a63ecb69c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='1', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1502eac-68e9-4cb7-acd3-4b5d37ea35c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"5\", \"5\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8a171-bae4-4a2d-a465-238f9dc5d742",
   "metadata": {},
   "source": [
    "# ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3d5ba-f308-44d0-885f-b5f0dd219912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationSummaryMemory 는 LLM 을 사용하여 대화의 요약본 (summary) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ca02db-9cc5-42e0-97b4-62088a031297",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2816f1b-1732-4f9f-b2f5-0941c36b228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain.memory.summary import ConversationSummaryMemory\n",
    "# https://python.langchain.com/api_reference/langchain/memory/langchain.memory.summary.ConversationSummaryMemory.html#langchain.memory.summary.ConversationSummaryMemory\n",
    "\n",
    "# Continually summarizes the conversation history.\n",
    "# The summary is updated after each conversation turn.\n",
    "# The implementations returns a summary of the conversation history\n",
    "# which can be used to provide context to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb7e96ca-e61b-4225-b083-fcf77b7a398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23164\\3817587095.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm = llm)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryMemory(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d1a2ddc-fbc1-44f4-8f32-e2c452c46071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 하나 만들어 두고..\n",
    "\n",
    "def get_history():\n",
    "  return memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18403428-0d6d-4fa0-94e2-0ec39d292cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message 추가\n",
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23297e98-e0d9-452a-af89-f658467aa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또 message 추가\n",
    "add_message(\n",
    "    \"South Korea is so pretty\",\n",
    "    \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f215f1ed-f5e7-454c-9fb6-32afc902b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'John introduces himself as living in South Korea. The AI responds by expressing admiration for his location, wishing it could go there.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9438dd7-4264-4492-8ae5-87c426d44f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↑ 대화를 '요약' 한 내용으로 기억하고 있다\n",
    "# 대화의 turn 이 길어질수로 summary 가 각 메세지를 효율적으료 '요약(압축)' 해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b44d26-eefa-4f0e-ad03-aca4fd7f6c87",
   "metadata": {},
   "source": [
    "# ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03419fb-c9ed-4ce5-bc73-507248c06f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain.memory.summary_buffer import ConversationSummaryBufferMemory\n",
    "# https://python.langchain.com/api_reference/langchain/memory/langchain.memory.summary_buffer.ConversationSummaryBufferMemory.html#langchain.memory.summary_buffer.ConversationSummaryBufferMemory\n",
    "\n",
    "# Buffer with summarizer for storing conversation memory.\n",
    "# Provides a running summary of the conversation together with\n",
    "#  the most recent messages in the conversation under the constraint\n",
    "#   that the total number of tokens in the conversation does not exceed a certain limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed3aa1-f2dc-49fc-8029-88413479896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConversationSummaryBufferMemory 는\n",
    "#   ConversationBufferMemory 와 ConversationSummaryMemory 의 결합형\n",
    "\n",
    "# 메모리에 보내온 '메세지의 수'를 지정하여 저장한다.\n",
    "# 오래된 메세지들 또한 '요약' 하여 저장함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bcbc11a-5f6e-4ef9-8e9b-6b95858e7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2305747e-ac6c-4ee5-ab4e-28bab70b771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23164\\3924822954.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,   # 최대 가용한 메세지 토큰수 (메세지 요약되기 전)\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b86b26-87ae-4f3b-b628-0aa1fd5862fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a161b9e-87c2-47fa-aff8-bfe99c850bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\n",
    "    \"South Korea is so pretty\",\n",
    "    \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56728c41-b229-4a4e-a1f3-3659101e5e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm John, I live in South Korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\n",
    "    \"How far is Korea from Argentina?\",\n",
    "    \"I don't know! Super far!\"\n",
    ")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8202495b-538f-4b72-9877-8f8a0f1638ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces himself as John and mentions he lives in South Korea.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South Korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래 셀을 여러차레 해보자  약 (3,4번?)\n",
    "# =>실제 '요약'이 발생할때면 Model IO 가 발생하기 때문에 시간이 좀 걸리는게 느껴질거다!\n",
    "\n",
    "add_message(\n",
    "    \"How far is Brazil from Argentina?\",\n",
    "    \"I don't know! Super far!\"\n",
    ")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d9823-79bc-4902-8481-1369dec46bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit 에 도달하면, 오래된 메세지들이 요약되고 있을 것을 확인할수 있다. (SystemMessage 확인)\n",
    "\n",
    "# ★그러나 '요약' 이라는 과정은 API 를 사용한다는 사실을 명심하세요.\n",
    "# ★'요약' 동작은 비용 지출이 발생되는 부분입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206af78a-5d46-4465-bb10-3310fd9d23ad",
   "metadata": {},
   "source": [
    "# ConversationKGMemory\n",
    "Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b500958-98b5-4122-a320-baca11bba15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_community.memory.kg import ConversationKGMemory\n",
    "# https://python.langchain.com/api_reference/community/memory/langchain_community.memory.kg.ConversationKGMemory.html\n",
    "\n",
    "# Knowledge graph conversation memory.\n",
    "# Integrates with external knowledge graph to store and retrieve information about knowledge triples in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c83d4-7b03-4da5-9679-035804b1463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화중에 '엔티티'의 knowledge graph 를 형성한다 => 가장 중요한 것들만 추출한 요약본.\n",
    "# knowledge graph 는 history 를 가지고 오지 않는다.  대신 '엔티티' 를 가지고 옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c0b1b79-1cb0-4a6e-8a70-de2ba2b20972",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8eadd9bd-9fa8-49bb-90ca-c26df40e0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\n",
    "    \"Hi I'm John, I live in South Korea\",    # input\n",
    "    \"Wow that is so cool!\"  # output : AI 답변\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc5d77f1-3de1-4803-8628-b0b7270901bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On John: John lives in South Korea.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({'input': 'who is John'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe2c45b-b4c6-4810-b681-4f24646bf3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 메세지를 더해보자\n",
    "add_message(\"John likes kimchi\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae23713b-2193-4046-a6ef-77e12211ccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On John: John lives in South Korea. John likes kimchi.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({'input': 'What does John like'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201241c7-e5cb-427a-8a68-766b804e50a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d76371-3ac4-4a29-ba06-d4565239ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c8694-1530-4906-bd19-3f92aa0fb201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084bfb0b-6781-422b-a129-b3ec2cf3e466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65763c-a83e-41b5-8c5a-8b91c7b9c094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae9824-0ea3-4cbe-8093-fdc35a8df080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442034a3-49f2-4bb6-8543-7f32f1819e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac5899-1f43-443a-aac7-b7b5d6bcfb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0520a78-609c-4db3-afc2-a01f258ebae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60a9cd-c6f9-41d2-bb87-3c3745534fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3131b9-b901-41fe-a62e-fe544b0b05b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e9d34-c2d4-47f9-8b87-de81f5985e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d13e3-0dd2-4705-99b6-d067ecb0664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c373e-a62c-4bc2-b3ce-72e06d80e497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47604fdb-6a57-46ae-a0e0-37f8e9538172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1487a47-40d9-458a-b91e-4dd0010a9b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a4391-af0a-4101-ac06-1f147152b38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749dc35-204d-4fe2-b607-ba441994023d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5cf9a-e884-41c0-9f42-1585e1d1bb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e133226-0a93-428f-a422-981095cc23e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfed98a-3695-4a62-a44b-6b2ca5a1f3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38aea5f-f94f-485e-a587-c1a5fd0802a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f75854-2390-445a-a70d-1bcd3795b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81329f6b-c7f5-42ab-b03a-a237ec7e3e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8e5b9-32fb-424a-a7be-4ab220ac7cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b29089-eefc-4aaf-b424-27164efeaf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2748f-3e52-4771-99b4-13663adf14af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f7c44-ba12-426e-98d5-e8871593b1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db24bf5-3153-45c7-abe0-f5f9926a9ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5840d5-a37f-44bc-800f-9b8b44d3672c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552139c0-704f-4f4f-9c8c-e4f9509a0f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e93f50-21a5-42a5-a51a-07c5e88ddefd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
