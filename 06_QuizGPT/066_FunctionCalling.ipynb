{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23854ca7-3cfb-4c8a-a4bf-46ef4c68b81b",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "- Function Calling은 OpenAI API에서 특정 함수 정의(JSON schema 기반)를 주고, 모델이 해당 함수를 호출하는 형식의 응답을 생성하게 하는 기능입니다.\n",
    "- 챗봇, 에이전트(Agent), 도구(Tool) 사용 등 다양한 자동화 및 플러그인 연동에 활용됩니다.\n",
    "\n",
    "- 지원 모델 gpt-3-turbo, gpt-4, gpt-4-turbo  (2025.1 현재)\n",
    "\n",
    "- 모델이 우리의 코드를 호출하도록 해서 우리의 함수들을 모델이 호출할수 있도록 하거나\n",
    "- 모델이 우리가 원하는 특정 모양과 형식의 output 을 갖도록 강제할수 있다.\n",
    "\n",
    "- https://platform.openai.com/docs/guides/function-calling?api-mode=chat\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99fc847-acc7-4e86-b8ea-72976ef976f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=sk-proj-iKU13YeoxNgF\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(f'OPENAI_API_KEY={os.getenv(\"OPENAI_API_KEY\")[:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ff9ffe-30f6-4e59-8b0a-5fddfd0d542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7677615d-e064-4385-90c8-3edc5d91c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I am not able to provide real-time weather updates. I recommend checking a reliable weather website or app for the most up-to-date information on the weather in Rome.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1, \n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Who is the weather in {city}\")  # Who 맞다.\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"city\": \"rome\"\n",
    "})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d74e6-1009-4572-a250-f372d30809f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실시간으로 날씨를 가져올수 없다.\n",
    "# 하지만!  이제 함수가 있다고 생각해보자.  실시간 데이터를 가져올 수 잇는 함수 말이다!\n",
    "#  함수에 필요한 정보는 아마 '장소' 정보 뿐 일거다.  (위도, 경도..)\n",
    "\n",
    "# ↓여기에 함수가 있다고 가정하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab50ae50-50aa-4f8f-b17c-01bd045ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓ 이러한 함수가 있다고 가정하자\n",
    "#   위도,경도를 주면 실시간 날씨 정보를 리턴하는 함수..\n",
    "def get_weather(lon, lat):\n",
    "    print(f\"call an api...lon:{lon}, lat:{lat}\")\n",
    "\n",
    "# ↓ LLM 에게 우리에게는 '이러이러한 동작' 을 해주는 함수가 있다고 알려주어야 한다\n",
    "#   함수를 JSON schema 로 정의!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbce207-b9e2-49b6-9ee4-8898e10ed452",
   "metadata": {},
   "source": [
    "# 함수의 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba827a97-c829-451a-9623-17012d538946",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_schema = {\n",
    "    \"name\": \"get_weather\",  # 함수의 이름\n",
    "\n",
    "    # description : 함수가 무슨 일을 하는지 기술\n",
    "    # ↓'위도와 경도를 받아서 특정장소의 날씨정보를 가져오는 함수\"\n",
    "    \"description\": \"function that takes longitude and latitude to find the weather of a place\",  \n",
    "\n",
    "    # 파라미터 기술\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            # 경도\n",
    "            \"lon\": {\"type\": \"string\", \"description\": \"The longitude coordinate\",},\n",
    "            # 위도\n",
    "            \"lat\": {\"type\": \"string\",\"description\": \"The latitude coordinate\",},\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # 필수 사항 기술\n",
    "    \"required\": [\"lon\", 'lat'],  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ab6ab-e9bf-45ba-801e-51ab27e6b038",
   "metadata": {},
   "source": [
    "# ChatOpenAI 에 함수 전달하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1a8631-b6e9-4d05-a60c-428c3580070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ").bind(  # ChatOpenAI 에게 전달할 인수를 추가해줄수 있다.\n",
    "    functions=[  # 원하는 만큼 많은 함수를 전달해 줄수 있다\n",
    "        function_schema,   # 준비한 schema 를 전달!\n",
    "    ],\n",
    "\n",
    "    # ↓기본적으로 모델이 특정 함수를 사용하도록 '강제'하거나, \n",
    "    #   모델이 함수를 사용하도록 하거나 그냥 답변을 할 수 있도록 모델 스스로 선택하게 할수 있다.\n",
    "\n",
    "    # 모델을 강제로 함수를 사용하도록 하려면! 아래와 같이 해야 한다\n",
    "    # function_call={  \n",
    "    #     \"name\": \"get_weather\",  # <-- get_weather 함수를 반드시 사용하라!        \n",
    "    # },\n",
    "    \n",
    "    # AI에 선택권을 주어 필요에 따라 선택하여 함수를 사용하게 함.\n",
    "    function_call='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be40071-cd84-40b1-baff-05e35ea7cfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"lon\":\"12.4964\",\"lat\":\"41.9028\"}', 'name': 'get_weather'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 74, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BwSWX6dM7lLk5NvGuOcLJZDax9TaH', 'finish_reason': 'function_call', 'logprobs': None}, id='run--4ad219bc-50fc-4b4a-bfec-45a81c7e3e11-0', usage_metadata={'input_tokens': 74, 'output_tokens': 24, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"city\": \"rome\"\n",
    "})\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44748dee-7481-4de3-b58a-c84f0f7001ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'arguments': '{\"lon\":\"12.4964\",\"lat\":\"41.9028\"}',\n",
       "  'name': 'get_weather'},\n",
       " 'refusal': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55ec429-67ae-413c-8d5f-032cb3f44d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"lon\":\"12.4964\",\"lat\":\"41.9028\"}', 'name': 'get_weather'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.additional_kwargs['function_call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77cc1f3-ee43-43da-841c-df6788da2c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"lon\":\"12.4964\",\"lat\":\"41.9028\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.additional_kwargs['function_call']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c667225-7909-46a7-acdc-bcf29bdfad0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lon': '12.4964', 'lat': '41.9028'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "r = json.loads(response.additional_kwargs['function_call']['arguments'])\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87066fea-cc47-4437-8b68-90c51ade730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('12.4964', '41.9028')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['lon'], r['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074cf1f0-8bd9-42c6-ab9d-1b6747920636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call an api...lon:12.4964, lat:41.9028\n"
     ]
    }
   ],
   "source": [
    "get_weather(r['lon'], r['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e53cd7-174d-4b90-b17c-4a5c46f91b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call an api...lon:12.4964, lat:41.9028\n"
     ]
    }
   ],
   "source": [
    "get_weather(**r)  # argument unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7796eefb-4c5d-4dd9-ac14-236a0824847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call an api...lon:126.9779, lat37.5665\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models.base import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "import json\n",
    "\n",
    "def get_weather(lon, lat):\n",
    "    print(f\"call an api...lon:{lon}, lat{lat}\")  \n",
    "\n",
    "function_schema = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"function that takes longitude and latitude to find the weather of a place\",  \n",
    "    \n",
    "    \"parameters\": { \n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"lon\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The longitude coordinate\",\n",
    "            },\n",
    "            \"lat\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The latitude coordinate\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"required\": [\"lon\", \"lat\"],\n",
    "}    \n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ").bind(\n",
    "    functions=[\n",
    "        function_schema\n",
    "    ],\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Who is the weather in {city}\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"city\": \"Seoul\"\n",
    "})\n",
    "\n",
    "r = json.loads(response.additional_kwargs['function_call']['arguments'])\n",
    "get_weather(**r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30738f0a-27e2-4f4e-b1c4-7c2a0ebb2e82",
   "metadata": {},
   "source": [
    "# 퀴즈 생성하기 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2d536c4-4049-4e42-bdbc-886e0fe85735",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_schema = {\n",
    "    \"name\": \"create_quiz\",\n",
    "    # ↓ 완전히 지어낸 함수다!\n",
    "    \"description\": \"function that takes a list of questions and answers and returns a quiz\",  \n",
    "\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "# ↓ 우라기 원하는 답변의 스키마는\n",
    " \n",
    "# 바로 이 형태를 정의하는 거다. \n",
    "# {\n",
    "#   \"questions\":[\n",
    "#      0:{\n",
    "#        \"question\":\"What … in the story?\"\n",
    "#        \"answers\":[\n",
    "#           0:{\n",
    "#             \"answer\":\"John\"\n",
    "#             \"correct\":false\n",
    "#           }\n",
    "#           ... \n",
    "#        ]\n",
    "#      }\n",
    "#      ...\n",
    "# }     \n",
    "\n",
    "            \"questions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"answers\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"answer\": { \"type\": \"string\"},\n",
    "                                    \"correct\": { \"type\": \"boolean\"},\n",
    "                                },\n",
    "                                \"required\": [\"answer\", \"correct\"],\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"question\", \"answers\"]\n",
    "                },\n",
    "            },\n",
    "        },        \n",
    "    },\n",
    "    \"required\": [\"questions\"],  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b03ab11f-9a01-4925-8e26-d8b4ac085d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': [{'question': 'What is the capital city of Italy?',\n",
       "   'answers': [{'answer': 'Rome', 'correct': True},\n",
       "    {'answer': 'Milan', 'correct': False},\n",
       "    {'answer': 'Florence', 'correct': False}]},\n",
       "  {'question': 'Which ancient Roman structure is known for its gladiator contests?',\n",
       "   'answers': [{'answer': 'Colosseum', 'correct': True},\n",
       "    {'answer': 'Pantheon', 'correct': False},\n",
       "    {'answer': 'Trevi Fountain', 'correct': False}]},\n",
       "  {'question': 'Who was the first Roman Emperor?',\n",
       "   'answers': [{'answer': 'Julius Caesar', 'correct': False},\n",
       "    {'answer': 'Augustus', 'correct': True},\n",
       "    {'answer': 'Nero', 'correct': False}]},\n",
       "  {'question': 'What river runs through the city of Rome?',\n",
       "   'answers': [{'answer': 'Tiber River', 'correct': True},\n",
       "    {'answer': 'Arno River', 'correct': False},\n",
       "    {'answer': 'Po River', 'correct': False}]},\n",
       "  {'question': 'Which famous Roman general crossed the Alps with elephants?',\n",
       "   'answers': [{'answer': 'Julius Caesar', 'correct': False},\n",
       "    {'answer': 'Hannibal', 'correct': True},\n",
       "    {'answer': 'Scipio Africanus', 'correct': False}]}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ").bind(\n",
    "    functions=[function_schema],\n",
    "    function_call={\n",
    "        \"name\": \"create_quiz\",\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Make a quiz about {city}\")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\n",
    "    \"city\": \"Rome\"\n",
    "})\n",
    "\n",
    "response = json.loads(response.additional_kwargs['function_call']['arguments'])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd202c-13e7-4dbc-990f-8c466ff019f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 형태의 출력을 하려면?\n",
    "#  example + output parser 와  function calling 두가지중 선택해볼수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122988fb-7115-4c7c-aa23-e1224fcedf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba64da-fdcc-4c6d-a087-d852268eccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368878d-e4f4-47a8-b630-47ce5da4ca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663a443-72a6-42b9-b5c5-71fba3fd4e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a939cd8-ae45-4f64-bf7e-c23cc2be688f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b1be0-d14b-4fb2-aa81-154cd3ac876a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0c4b8-8395-4f54-afe0-87ba240aa949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2e63b-b5e5-4722-a1fe-af7bc3141ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261fe40-c4d3-491d-a68a-3844e291d308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a3385-d4d4-468b-a98a-0552cd1bce51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59019619-2d3e-477f-b48d-0984092a4213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759bfff-b6f5-468f-a1dd-a9a9193ed2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820b2d1-db23-4f37-830b-bf585bd9be6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313d26a-e2b8-4200-b764-f537dde7a5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f9371-d030-44fe-9d9b-a287302b9eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ef33f-f191-4e69-8da4-06d598fffca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b8410-d920-4c3b-bf7c-3a6dab668866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed53c7-b2db-4c47-a067-7795e0a8fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915568b-a6af-464a-b370-6773d0acef02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868ae0b-8237-4a9c-a306-ac2366310935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fccff4a-324e-4441-81e2-2ac56f83411c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32173095-e248-46bd-a557-98029f9f4346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc27b71-eede-4829-b444-f67a32d347e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597158fb-911e-436e-9334-405ce70fa43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a070795-e6c8-4f68-addd-d890446ef5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4d54f-fa8e-4f56-ac88-d0e0087f854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e8b77-9a6b-4d11-bc50-290d3187a215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c49d6-3e2e-4ecd-9205-b964857e5e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d4fd9-72c2-43b4-8cc2-69dd45838af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9995e-59f7-4d42-8de8-712e970d109b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e080e2-0ef0-438b-8874-6933eb1345e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
